{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QgumzOZ5wgec",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Production model training with K-Folds cross-validation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6eM1BMvDwgee",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook shows how you can use the Evidently to:\n",
    "* calculate prerformance and data drift for the model, performed as batch checks \n",
    "* log models quality & data drift using MLflow Tracking\n",
    "* explore the result \n",
    "\n",
    "More examples are avaliable in the github: https://github.com/evidentlyai/evidently/tree/main/examples\n",
    "\n",
    "Evidently docs: https://docs.evidentlyai.com/\n",
    "\n",
    "Join our Discord: https://discord.com/invite/xZjKRaNp8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rByuPhg7wgei",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn import datasets, ensemble, model_selection\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from evidently.metrics import RegressionQualityMetric, RegressionErrorPlot, RegressionErrorDistribution\n",
    "from evidently.metric_preset import DataDriftPreset, RegressionPreset\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.report import Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HiiUl3p8wgej",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zw5Tap_Xwgej",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bicycle Demand Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VqGH1Mr6wgej",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "More information about the dataset can be found in UCI machine learning repository: https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset\n",
    "\n",
    "Acknowledgement: Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "36Gk-YMhwgek",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data saved in the previous step (in train_model.ipynb)\n",
    "\n",
    "raw_data = pd.read_csv('../data/raw_data.csv', index_col=0)\n",
    "# raw_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dKX2YV19wgek",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# content = requests.get(\"https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip\").content\n",
    "# with zipfile.ZipFile(io.BytesIO(content)) as arc:\n",
    "#     raw_data = pd.read_csv(arc.open(\"hour.csv\"), header=0, sep=',', parse_dates=['dteday']) \n",
    "    \n",
    "# raw_data.index = raw_data.apply(lambda row: datetime.datetime.combine(row.dteday.date(), datetime.time(row.hr)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N6oQxQKNwgek",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     instant      dteday  season  yr  mnth  hr  holiday  \\\n",
       "2011-01-01 00:00:00        1  2011-01-01       1   0     1   0        0   \n",
       "2011-01-01 01:00:00        2  2011-01-01       1   0     1   1        0   \n",
       "2011-01-01 02:00:00        3  2011-01-01       1   0     1   2        0   \n",
       "2011-01-01 03:00:00        4  2011-01-01       1   0     1   3        0   \n",
       "2011-01-01 04:00:00        5  2011-01-01       1   0     1   4        0   \n",
       "\n",
       "                     weekday  workingday  weathersit  temp   atemp   hum  \\\n",
       "2011-01-01 00:00:00        6           0           1  0.24  0.2879  0.81   \n",
       "2011-01-01 01:00:00        6           0           1  0.22  0.2727  0.80   \n",
       "2011-01-01 02:00:00        6           0           1  0.22  0.2727  0.80   \n",
       "2011-01-01 03:00:00        6           0           1  0.24  0.2879  0.75   \n",
       "2011-01-01 04:00:00        6           0           1  0.24  0.2879  0.75   \n",
       "\n",
       "                     windspeed  casual  registered  cnt  \n",
       "2011-01-01 00:00:00        0.0       3          13   16  \n",
       "2011-01-01 01:00:00        0.0       8          32   40  \n",
       "2011-01-01 02:00:00        0.0       5          27   32  \n",
       "2011-01-01 03:00:00        0.0       3          10   13  \n",
       "2011-01-01 04:00:00        0.0       0           1    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Folds split setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dhZOCJZ1wgel",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_i8edS6Ewgem",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = 'cnt'\n",
    "prediction = 'prediction'\n",
    "datetime = 'dteday'\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed', 'mnth', 'hr', 'weekday']\n",
    "categorical_features = ['season', 'holiday', 'workingday', ]#'weathersit']\n",
    "\n",
    "column_mapping = ColumnMapping()\n",
    "column_mapping.target = target\n",
    "column_mapping.prediction = prediction\n",
    "column_mapping.datetime = datetime\n",
    "column_mapping.numerical_features = numerical_features\n",
    "column_mapping.categorical_features = categorical_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "q5lW24Xzwgex",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Quality Evaluation (Prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I_IyYlM0wgey",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "#import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# datetime.strptime('2011-03-06 23:00:00', '%Y-%m-%d %H:%M:%S').isoweekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "L6PKtAGEwgey",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_date_0 = '2011-01-02 00:00:00'\n",
    "end_date_0 = '2011-01-30 23:00:00'\n",
    "\n",
    "experiment_batches = [\n",
    "    \n",
    "    ('2011-01-31 00:00:00','2011-02-06 23:00:00'),\n",
    "    ('2011-02-07 23:00:00','2011-02-13 23:00:00'),\n",
    "    ('2011-02-14 23:00:00','2011-02-20 23:00:00'),\n",
    "    ('2011-02-21 00:00:00','2011-02-27 23:00:00'),\n",
    "    ('2011-02-28 00:00:00','2011-03-06 23:00:00'),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 17)\n"
     ]
    }
   ],
   "source": [
    "reference = raw_data.loc[start_date_0:end_date_0]\n",
    "print(reference.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yc0HhabLxYVj"
   },
   "outputs": [],
   "source": [
    "# # X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "# #     reference[numerical_features + categorical_features],\n",
    "# #     reference[target],\n",
    "# #     test_size=0.3\n",
    "# # )\n",
    "\n",
    "# # preds_train = regressor.predict(X_train)\n",
    "# # preds_test = regressor.predict(X_test)\n",
    "\n",
    "# X_train['target'] = y_train\n",
    "# X_train['prediction'] = preds_train\n",
    "\n",
    "# X_test['target'] = y_test\n",
    "# X_test['prediction'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = '../reports'\n",
    "\n",
    "model_path = Path('../models/model_get_started.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bTHU8eAqwgez",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client tracking uri: http://localhost:5000\n",
      "0 2011-01-31 00:00:00 2011-02-06 23:00:00\n",
      "train_end_data: 2011-01-30 23:00:00\n",
      "(640, 10) (640,)\n",
      "(165, 10) (165,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: 02cd3ce71c6a43e4bb4698e622659ff6\n",
      "Run name: blushing-jay-932\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/02cd3ce71c6a43e4bb4698e622659ff6/artifacts\n",
      "1 2011-02-07 23:00:00 2011-02-13 23:00:00\n",
      "train_end_data: 2011-02-06 23:00:00\n",
      "(805, 10) (805,)\n",
      "(140, 10) (140,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: 3e46eb9172c74a38ad71d3a59195ab1f\n",
      "Run name: capricious-slug-601\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/3e46eb9172c74a38ad71d3a59195ab1f/artifacts\n",
      "2 2011-02-14 23:00:00 2011-02-20 23:00:00\n",
      "train_end_data: 2011-02-13 23:00:00\n",
      "(968, 10) (968,)\n",
      "(142, 10) (142,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: ba1a5b603ae14704b22a00fb175d8029\n",
      "Run name: shivering-foal-855\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/ba1a5b603ae14704b22a00fb175d8029/artifacts\n",
      "3 2011-02-21 00:00:00 2011-02-27 23:00:00\n",
      "train_end_data: 2011-02-20 23:00:00\n",
      "(1133, 10) (1133,)\n",
      "(158, 10) (158,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: f39b308340cd4734bfee2728b032f224\n",
      "Run name: nebulous-shrimp-438\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/f39b308340cd4734bfee2728b032f224/artifacts\n",
      "4 2011-02-28 00:00:00 2011-03-06 23:00:00\n",
      "train_end_data: 2011-02-27 23:00:00\n",
      "(1291, 10) (1291,)\n",
      "(165, 10) (165,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: fd27558b436f44e295994e68bfee8129\n",
      "Run name: powerful-tern-825\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/fd27558b436f44e295994e68bfee8129/artifacts\n"
     ]
    }
   ],
   "source": [
    "from config import MLFLOW_TRACKING_URI\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")\n",
    "\n",
    "#set experiment\n",
    "mlflow.set_experiment('Train Model - K-Fold')\n",
    "\n",
    "ref_end_data = end_date_0\n",
    "\n",
    "#start new run\n",
    "for k, date in enumerate(experiment_batches):\n",
    "    \n",
    "    print(k, date[0],  date[1])\n",
    "    \n",
    "        \n",
    "    print(f\"train_end_data: {ref_end_data}\") \n",
    "    X_train = raw_data.loc[start_date_0:ref_end_data, numerical_features + categorical_features]\n",
    "    y_train = raw_data.loc[start_date_0:ref_end_data, target]\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    \n",
    "    current = raw_data.loc[date[0]:date[1]]\n",
    "    X_test = current.loc[:, numerical_features + categorical_features]\n",
    "    y_test = current[target]\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    \n",
    "    # Update reference end date\n",
    "    ref_end_data = date[1]\n",
    "    \n",
    "    regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    ref_prediction = regressor.predict(reference[numerical_features + categorical_features])\n",
    "    reference['prediction'] = ref_prediction\n",
    "    \n",
    "    prediction = regressor.predict(current[numerical_features + categorical_features])\n",
    "    current['prediction'] = prediction\n",
    "    \n",
    "    \n",
    "    # Get metrics\n",
    "    regression_performance_report = Report(metrics=[\n",
    "        RegressionQualityMetric(),\n",
    "    ])\n",
    "    regression_performance_report.run(\n",
    "        reference_data=reference, \n",
    "        current_data=current,\n",
    "        column_mapping=column_mapping)\n",
    "    # logged_json = json.loads(the_report.json())\n",
    "    \n",
    "    train_report_metrics = regression_performance_report.as_dict()\n",
    "    me = train_report_metrics['metrics'][0]['result']['current']['mean_error']\n",
    "    mae = train_report_metrics['metrics'][0]['result']['current'][\"mean_abs_error\"]\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(regressor, model_path)\n",
    "    model_quality_report_path = f\"{REPORTS_DIR}/model_quality_report.html\"\n",
    "    regression_performance_report.save_html(model_quality_report_path)\n",
    "\n",
    "    \n",
    "    with mlflow.start_run() as run: #inside brackets run_name='test'\n",
    "        \n",
    "        # Show newly created run metadata info\n",
    "        print(\"Experiment id: {}\".format(run.info.experiment_id))\n",
    "        print(\"Run id: {}\".format(run.info.run_id))\n",
    "        print(\"Run name: {}\".format(run.info.run_name))\n",
    "        print('MLFlow tracking uri:', mlflow.get_tracking_uri())\n",
    "        print('MLFlow artifact uri:', mlflow.get_artifact_uri())\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"begin\", date[0])\n",
    "        mlflow.log_param(\"end\", date[1])\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric('me', round(me, 3))\n",
    "        mlflow.log_metric('mae', round(mae, 3))\n",
    "        \n",
    "        # Log model \n",
    "        mlflow.log_artifact(model_path)\n",
    "        \n",
    "        # Log the regression_performance_report as an artifact\n",
    "        mlflow.log_artifact(model_quality_report_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client tracking uri: http://localhost:5000\n",
      "0 2011-01-31 00:00:00 2011-02-06 23:00:00\n",
      "train_end_data: 2011-01-30 23:00:00\n",
      "(640, 10) (640,)\n",
      "(165, 10) (165,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: 93acd3a154674b8f9b5daa16bd1844ad\n",
      "Run name: carefree-hog-133\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/88a1ddd94e594d60a4f4d19c380617f8/artifacts\n",
      "1 2011-02-07 23:00:00 2011-02-13 23:00:00\n",
      "train_end_data: 2011-02-06 23:00:00\n",
      "(805, 10) (805,)\n",
      "(140, 10) (140,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: 93acd3a154674b8f9b5daa16bd1844ad\n",
      "Run name: carefree-hog-133\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/d7503a5a149046f49c3d020f54304359/artifacts\n",
      "2 2011-02-14 23:00:00 2011-02-20 23:00:00\n",
      "train_end_data: 2011-02-13 23:00:00\n",
      "(968, 10) (968,)\n",
      "(142, 10) (142,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: 93acd3a154674b8f9b5daa16bd1844ad\n",
      "Run name: carefree-hog-133\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/e2666ee172a24fc5a8b9667f958d5323/artifacts\n",
      "3 2011-02-21 00:00:00 2011-02-27 23:00:00\n",
      "train_end_data: 2011-02-20 23:00:00\n",
      "(1133, 10) (1133,)\n",
      "(158, 10) (158,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: 93acd3a154674b8f9b5daa16bd1844ad\n",
      "Run name: carefree-hog-133\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/48056600e02a49ddb30e5e54306a5f7e/artifacts\n",
      "4 2011-02-28 00:00:00 2011-03-06 23:00:00\n",
      "train_end_data: 2011-02-27 23:00:00\n",
      "(1291, 10) (1291,)\n",
      "(165, 10) (165,)\n",
      "Experiment id: 155405333588197577\n",
      "Run id: 93acd3a154674b8f9b5daa16bd1844ad\n",
      "Run name: carefree-hog-133\n",
      "MLFlow tracking uri: http://localhost:5000\n",
      "MLFlow artifact uri: mlflow-artifacts:/155405333588197577/8794ae01c61a45c4bdfc0d15633ec31f/artifacts\n"
     ]
    }
   ],
   "source": [
    "from config import MLFLOW_TRACKING_URI\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "mlflow.set_experiment('Train Model - K-Fold')\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")\n",
    "\n",
    "ref_end_data = end_date_0\n",
    "\n",
    "# Start a new Run (Parent Run)\n",
    "with mlflow.start_run() as run: \n",
    "    \n",
    "    \n",
    "    metrics = {}\n",
    "\n",
    "    #start new run\n",
    "    for k, date in enumerate(experiment_batches):\n",
    "        \n",
    "        print(k, date[0],  date[1])\n",
    "            \n",
    "        print(f\"train_end_data: {ref_end_data}\") \n",
    "        X_train = raw_data.loc[start_date_0:ref_end_data, numerical_features + categorical_features]\n",
    "        y_train = raw_data.loc[start_date_0:ref_end_data, target]\n",
    "        print(X_train.shape, y_train.shape)\n",
    "        \n",
    "        current = raw_data.loc[date[0]:date[1]]\n",
    "        X_test = current.loc[:, numerical_features + categorical_features]\n",
    "        y_test = current[target]\n",
    "        print(X_test.shape, y_test.shape)\n",
    "        \n",
    "        # Update reference end date\n",
    "        ref_end_data = date[1]\n",
    "        \n",
    "        regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        \n",
    "        ref_prediction = regressor.predict(reference[numerical_features + categorical_features])\n",
    "        reference['prediction'] = ref_prediction\n",
    "        \n",
    "        prediction = regressor.predict(current[numerical_features + categorical_features])\n",
    "        current['prediction'] = prediction\n",
    "        \n",
    "        \n",
    "        # Get metrics\n",
    "        regression_performance_report = Report(metrics=[\n",
    "            RegressionQualityMetric(),\n",
    "        ])\n",
    "        regression_performance_report.run(\n",
    "            reference_data=reference, \n",
    "            current_data=current,\n",
    "            column_mapping=column_mapping)\n",
    "        # logged_json = json.loads(the_report.json())\n",
    "        \n",
    "        train_report_metrics = regression_performance_report.as_dict()\n",
    "        me = train_report_metrics['metrics'][0]['result']['current']['mean_error']\n",
    "        mae = train_report_metrics['metrics'][0]['result']['current'][\"mean_abs_error\"]\n",
    "        metrics.update({date[1]: {'me': me, 'mae': mae}})\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump(regressor, model_path)\n",
    "        model_quality_report_path = f\"{REPORTS_DIR}/model_quality_report.html\"\n",
    "        regression_performance_report.save_html(model_quality_report_path)\n",
    "        \n",
    "        # Run a Childe Run for each Fold \n",
    "        with mlflow.start_run(run_name=date[1], \n",
    "                              nested=True,\n",
    "                            #   experiment_id=experiment_id\n",
    "                              ) as child_run:\n",
    "            \n",
    "            # Show newly created run metadata info\n",
    "            print(\"Experiment id: {}\".format(run.info.experiment_id))\n",
    "            print(\"Run id: {}\".format(run.info.run_id))\n",
    "            print(\"Run name: {}\".format(run.info.run_name))\n",
    "            print('MLFlow tracking uri:', mlflow.get_tracking_uri())\n",
    "            print('MLFlow artifact uri:', mlflow.get_artifact_uri())\n",
    "            \n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"begin\", date[0])\n",
    "            mlflow.log_param(\"end\", date[1])\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric('me', round(me, 3))\n",
    "            mlflow.log_metric('mae', round(mae, 3))\n",
    "            \n",
    "            # Log the regression_performance_report as an artifact\n",
    "            mlflow.log_artifact(model_quality_report_path)\n",
    "            \n",
    "        # Log the last batch model as the parent Run model\n",
    "        mlflow.log_artifact(model_path)\n",
    "        \n",
    "        # Log metrics\n",
    "        average_run_merics = pd.DataFrame.from_dict(metrics).T.mean().round(3).to_dict()\n",
    "        mlflow.log_metrics(average_run_merics )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.reports import (\n",
    "    build_regression_quality_report,\n",
    "    get_regression_quality_metrics,\n",
    "    build_data_drift_report,\n",
    "    get_data_drift_metrics,\n",
    ")\n",
    "\n",
    "from src.plots import (\n",
    "    detect_dataset_drift,\n",
    "    detect_features_drift,\n",
    "    # plot_drifted_feature_scores,\n",
    "    # plot_drifted_features, \n",
    ")\n",
    "\n",
    "from src.reports import build_model_performance_test_report, get_test_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client tracking uri: http://localhost:5000\n",
      "Name: Data Drift\n",
      "Experiment ID: 234193429068143937\n",
      "Experiment Name: Data Drift\n",
      "Artifact Location: mlflow-artifacts:/234193429068143937\n",
      "Lifecycle_stage: active\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/234193429068143937', creation_time=1688577389525, experiment_id='234193429068143937', last_update_time=1688577389525, lifecycle_stage='active', name='Data Drift', tags={}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import MLFLOW_TRACKING_URI\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"Data Drift\"\n",
    "\n",
    "# Get or Create an experiment by name \n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment: \n",
    "    \n",
    "    experiment_id = experiment.experiment_id if experiment else None\n",
    "    # Show experiment info\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment ID: {}\".format(experiment.experiment_id))\n",
    "    print(\"Experiment Name: {}\".format(experiment.name))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Create_experiment\n",
    "    experiment_id = client.create_experiment(EXPERIMENT_NAME)\n",
    "    print(\"Experiment ID: {}\".format(experiment_id))\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment id: 234193429068143937\n",
      "Run id: ebe6e31439d84538a483a5e24c54a79f\n",
      "Run name: melodic-trout-704\n",
      "Batch: 0\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-01-30 23:00:00')\n",
      "Test (current) dates: ('2011-01-31 00:00:00', '2011-02-06 23:00:00')\n",
      "(640, 10) (640,)\n",
      "(165, 10) (165,)\n",
      "Run id: e2f48ca4ca88428f9366f921c72356af\n",
      "Run name: 2011-02-06 23:00:00\n",
      "Batch: 1\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-02-06 23:00:00')\n",
      "Test (current) dates: ('2011-02-07 23:00:00', '2011-02-13 23:00:00')\n",
      "(805, 10) (805,)\n",
      "(140, 10) (140,)\n",
      "Run id: 2315e6919d0148cdbf6d50ff3e0e5a0c\n",
      "Run name: 2011-02-13 23:00:00\n",
      "Batch: 2\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-02-13 23:00:00')\n",
      "Test (current) dates: ('2011-02-14 23:00:00', '2011-02-20 23:00:00')\n",
      "(968, 10) (968,)\n",
      "(142, 10) (142,)\n",
      "Run id: e066bc476c934583a88ba9a6f08a3665\n",
      "Run name: 2011-02-20 23:00:00\n",
      "Batch: 3\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-02-20 23:00:00')\n",
      "Test (current) dates: ('2011-02-21 00:00:00', '2011-02-27 23:00:00')\n",
      "(1133, 10) (1133,)\n",
      "(158, 10) (158,)\n",
      "Run id: 3702ef23920e4d008c98ee3255509677\n",
      "Run name: 2011-02-27 23:00:00\n",
      "Batch: 4\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-02-27 23:00:00')\n",
      "Test (current) dates: ('2011-02-28 00:00:00', '2011-03-06 23:00:00')\n",
      "(1291, 10) (1291,)\n",
      "(165, 10) (165,)\n",
      "Run id: cd49d3bdf971428ca717120623e2e8c2\n",
      "Run name: 2011-03-06 23:00:00\n",
      "Test failed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ref_end_data = end_date_0\n",
    "FEATURE_COLUMNS = numerical_features + categorical_features\n",
    "\n",
    "# Start a new Run (Parent Run)\n",
    "with mlflow.start_run() as run: \n",
    "    \n",
    "    # Show newly created run metadata info\n",
    "    print(\"Experiment id: {}\".format(run.info.experiment_id))\n",
    "    print(\"Run id: {}\".format(run.info.run_id))\n",
    "    print(\"Run name: {}\".format(run.info.run_name))\n",
    "    \n",
    "    metrics_model = {}\n",
    "    metrics_data = {}\n",
    "    metrics_test = {}\n",
    "    features_historical_drift = []\n",
    "    features_historical_drift_pvalues = []\n",
    "    test_status = 0\n",
    "\n",
    "    #start new run\n",
    "    for k, test_dates in enumerate(experiment_batches):\n",
    "        \n",
    "        print(f\"Batch: {k}\")\n",
    "        \n",
    "        train_dates = start_date_0, ref_end_data\n",
    "        ref_end_data = test_dates[1] # Update reference end date for the next train batch \n",
    "        print(f\"Train dates: {train_dates}\") \n",
    "        print(f\"Test (current) dates: {test_dates}\") \n",
    "        \n",
    "        train_data = raw_data.loc[train_dates[0]:train_dates[1]]\n",
    "        X_train = train_data.loc[:, FEATURE_COLUMNS]\n",
    "        y_train = train_data.loc[:, target]\n",
    "        print(X_train.shape, y_train.shape)\n",
    "        \n",
    "        test_data = raw_data.loc[test_dates[0]:test_dates[1]]\n",
    "        X_test = test_data.loc[:, FEATURE_COLUMNS]\n",
    "        y_test = test_data[target]\n",
    "        print(X_test.shape, y_test.shape)\n",
    "        \n",
    "        # Train model\n",
    "        regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        \n",
    "        # Calculate predictions\n",
    "        ref_prediction = regressor.predict(train_data[FEATURE_COLUMNS])\n",
    "        train_data['prediction'] = ref_prediction\n",
    "        cur_prediction = regressor.predict(test_data[FEATURE_COLUMNS])\n",
    "        test_data['prediction'] = cur_prediction\n",
    "        \n",
    "        \n",
    "        # Calculate Model Quality metrics\n",
    "        regression_quality_report = build_regression_quality_report(\n",
    "            reference_data=train_data, \n",
    "            current_data=test_data,\n",
    "            column_mapping=column_mapping\n",
    "        )\n",
    "        train_metrics = get_regression_quality_metrics(regression_quality_report)\n",
    "        metrics_model.update({test_dates[1]: train_metrics})\n",
    "        \n",
    "        # Calculate Data Drift metrics\n",
    "        data_drift_report = build_data_drift_report(\n",
    "            reference_data=X_train.reset_index(drop=True), \n",
    "            current_data=X_test.reset_index(drop=True),\n",
    "            column_mapping=column_mapping,\n",
    "            drift_share=0.4\n",
    "        )\n",
    "        data_drift_metrics: Dict = get_data_drift_metrics(data_drift_report)\n",
    "        metrics_data.update({test_dates[1]: data_drift_metrics})\n",
    "        \n",
    "        model_quality_report_path = f\"{REPORTS_DIR}/model_quality_report.html\"\n",
    "        regression_quality_report.save_html(model_quality_report_path)\n",
    "        \n",
    "        # Run a Child Run for each Fold \n",
    "        with mlflow.start_run(run_name=test_dates[1], \n",
    "                              nested=True,\n",
    "                              ) as nested_run:\n",
    "            \n",
    "            # Show newly created run metadata info\n",
    "            print(\"Run id: {}\".format(nested_run.info.run_id))\n",
    "            print(\"Run name: {}\".format(nested_run.info.run_name))\n",
    "\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"begin\", test_dates[0])\n",
    "            mlflow.log_param(\"end\", test_dates[1])\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metrics(train_metrics)\n",
    "            mlflow.log_metrics(data_drift_metrics)\n",
    "            \n",
    "            # Log the regression_quality_report as an artifact\n",
    "            mlflow.log_artifact(model_quality_report_path)\n",
    "            \n",
    "            # Log Data Drift report ONLY if drift is detected\n",
    "            if data_drift_metrics['dataset_drift'] is True:\n",
    "                report_date = test_dates[1].split(' ')[0]\n",
    "                data_drift_report_path = f\"../reports/data_drift_report_{report_date}.html\"\n",
    "                data_drift_report.save_html(data_drift_report_path)\n",
    "                mlflow.log_artifact(data_drift_report_path)\n",
    "            \n",
    "    \n",
    "    # Save final  model\n",
    "    joblib.dump(regressor, model_path)\n",
    "    \n",
    "    # Log the last batch model as the parent Run model\n",
    "    mlflow.log_artifact(model_path)\n",
    "    \n",
    "    # Log metrics\n",
    "    avg_model_metrics = pd.DataFrame.from_dict(metrics_model).T.mean().round(3).to_dict()\n",
    "    mlflow.log_metrics(avg_model_metrics)\n",
    "    \n",
    "    avg_data_metrics = pd.DataFrame.from_dict(metrics_data).T.mean().round(3).to_dict()\n",
    "    mlflow.log_metrics(avg_data_metrics)\n",
    "    \n",
    "    # Test the final model \n",
    "    model_test_report = build_model_performance_test_report(\n",
    "        current_data=current,\n",
    "        column_mapping=column_mapping,\n",
    "    )\n",
    "    test_status = get_test_status(model_test_report)\n",
    "    if test_status == 0:\n",
    "        print(\"Test failed\")\n",
    "        model_test_report_path = f\"../reports/model_test_report_report.html\"\n",
    "        model_test_report.save_html(model_test_report_path)\n",
    "        mlflow.log_artifact(model_test_report_path)\n",
    "    mlflow.log_metric(\"test_status\", test_status)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
