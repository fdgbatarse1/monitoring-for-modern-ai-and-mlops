{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QgumzOZ5wgec",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Production model training with K-Folds cross-validation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6eM1BMvDwgee",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook shows how you can use the Evidently to:\n",
    "* calculate prerformance and data drift for the model, performed as batch checks \n",
    "* log models quality & data drift using MLflow Tracking\n",
    "* explore the result \n",
    "\n",
    "More examples are avaliable in the github: https://github.com/evidentlyai/evidently/tree/main/examples\n",
    "\n",
    "Evidently docs: https://docs.evidentlyai.com/\n",
    "\n",
    "Join our Discord: https://discord.com/invite/xZjKRaNp8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rByuPhg7wgei",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datetime\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn import datasets, ensemble, model_selection\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from evidently.metrics import RegressionQualityMetric, RegressionErrorPlot, RegressionErrorDistribution\n",
    "from evidently.metric_preset import DataDriftPreset, RegressionPreset\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.report import Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HiiUl3p8wgej",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zw5Tap_Xwgej",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bicycle Demand Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VqGH1Mr6wgej",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "More information about the dataset can be found in UCI machine learning repository: https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset\n",
    "\n",
    "Acknowledgement: Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "36Gk-YMhwgek",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# content = requests.get(\"https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip\").content\n",
    "# with zipfile.ZipFile(io.BytesIO(content)) as arc:\n",
    "#     raw_data = pd.read_csv(arc.open(\"hour.csv\"), header=0, sep=',', parse_dates=['dteday']) \n",
    "    \n",
    "# raw_data.index = raw_data.apply(lambda row: datetime.datetime.combine(row.dteday.date(), datetime.time(row.hr)), axis=1)\n",
    "\n",
    "# Load data saved in the previous step (in train_model.ipynb)\n",
    "raw_data = pd.read_csv('../data/raw_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N6oQxQKNwgek",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     instant      dteday  season  yr  mnth  hr  holiday  \\\n",
       "2011-01-01 00:00:00        1  2011-01-01       1   0     1   0        0   \n",
       "2011-01-01 01:00:00        2  2011-01-01       1   0     1   1        0   \n",
       "2011-01-01 02:00:00        3  2011-01-01       1   0     1   2        0   \n",
       "2011-01-01 03:00:00        4  2011-01-01       1   0     1   3        0   \n",
       "2011-01-01 04:00:00        5  2011-01-01       1   0     1   4        0   \n",
       "\n",
       "                     weekday  workingday  weathersit  temp   atemp   hum  \\\n",
       "2011-01-01 00:00:00        6           0           1  0.24  0.2879  0.81   \n",
       "2011-01-01 01:00:00        6           0           1  0.22  0.2727  0.80   \n",
       "2011-01-01 02:00:00        6           0           1  0.22  0.2727  0.80   \n",
       "2011-01-01 03:00:00        6           0           1  0.24  0.2879  0.75   \n",
       "2011-01-01 04:00:00        6           0           1  0.24  0.2879  0.75   \n",
       "\n",
       "                     windspeed  casual  registered  cnt  \n",
       "2011-01-01 00:00:00        0.0       3          13   16  \n",
       "2011-01-01 01:00:00        0.0       8          32   40  \n",
       "2011-01-01 02:00:00        0.0       5          27   32  \n",
       "2011-01-01 03:00:00        0.0       3          10   13  \n",
       "2011-01-01 04:00:00        0.0       0           1    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Folds split setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dhZOCJZ1wgel",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_i8edS6Ewgem",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = 'cnt'\n",
    "prediction = 'prediction'\n",
    "datetime = 'dteday'\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed', 'mnth', 'hr', 'weekday']\n",
    "categorical_features = ['season', 'holiday', 'workingday', ]#'weathersit']\n",
    "\n",
    "column_mapping = ColumnMapping()\n",
    "column_mapping.target = target\n",
    "column_mapping.prediction = prediction\n",
    "column_mapping.datetime = datetime\n",
    "column_mapping.numerical_features = numerical_features\n",
    "column_mapping.categorical_features = categorical_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "q5lW24Xzwgex",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Quality Evaluation (Prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "I_IyYlM0wgey",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "#import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "L6PKtAGEwgey",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_date_0 = '2011-01-02 00:00:00'\n",
    "end_date_0 = '2011-01-30 23:00:00'\n",
    "\n",
    "experiment_batches = [\n",
    "    \n",
    "    ('2011-01-31 00:00:00','2011-02-06 23:00:00'),\n",
    "    ('2011-02-07 23:00:00','2011-02-13 23:00:00'),\n",
    "    ('2011-02-14 23:00:00','2011-02-20 23:00:00'),\n",
    "    ('2011-02-21 00:00:00','2011-02-27 23:00:00'),\n",
    "    ('2011-02-28 00:00:00','2011-03-06 23:00:00'),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 17)\n"
     ]
    }
   ],
   "source": [
    "reference = raw_data.loc[start_date_0:end_date_0]\n",
    "print(reference.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = '../reports'\n",
    "\n",
    "model_path = Path('../models/model.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.reports import (\n",
    "    build_regression_quality_report,\n",
    "    get_regression_quality_metrics,\n",
    "    build_data_drift_report,\n",
    "    get_data_drift_metrics,\n",
    ")\n",
    "\n",
    "from src.plots import (\n",
    "    detect_dataset_drift,\n",
    "    detect_features_drift,\n",
    "    # plot_drifted_feature_scores,\n",
    "    # plot_drifted_features, \n",
    ")\n",
    "\n",
    "from src.reports import build_model_performance_test_report, get_test_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client tracking uri: http://localhost:5000\n",
      "Experiment ID: 512570806058847602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/512570806058847602', creation_time=1688654691939, experiment_id='512570806058847602', last_update_time=1688654691939, lifecycle_stage='active', name='Test Model', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import MLFLOW_TRACKING_URI\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")\n",
    "\n",
    "# Get or Create an experiment by name \n",
    "EXPERIMENT_NAME = \"Test Model\"\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment: \n",
    "    \n",
    "    experiment_id = experiment.experiment_id if experiment else None\n",
    "    # Show experiment info\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment ID: {}\".format(experiment.experiment_id))\n",
    "    print(\"Experiment Name: {}\".format(experiment.name))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Create_experiment\n",
    "    experiment_id = client.create_experiment(EXPERIMENT_NAME)\n",
    "    print(\"Experiment ID: {}\".format(experiment_id))\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment id: 512570806058847602\n",
      "Run id: f23e2040ace24e20a937e9c116644292\n",
      "Run name: auspicious-yak-26\n",
      "Batch: 0\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-01-30 23:00:00')\n",
      "Test (current) dates: ('2011-01-31 00:00:00', '2011-02-06 23:00:00')\n",
      "(640, 10) (640,)\n",
      "(165, 10) (165,)\n",
      "Run id: a02fddd0e1d24ad290af9f005e25dc70\n",
      "Run name: 2011-02-06 23:00:00\n",
      "Batch: 1\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-02-06 23:00:00')\n",
      "Test (current) dates: ('2011-02-07 23:00:00', '2011-02-13 23:00:00')\n",
      "(805, 10) (805,)\n",
      "(140, 10) (140,)\n",
      "Run id: cbb1c663f2eb4557a8779a7999e843fa\n",
      "Run name: 2011-02-13 23:00:00\n",
      "Batch: 2\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-02-13 23:00:00')\n",
      "Test (current) dates: ('2011-02-14 23:00:00', '2011-02-20 23:00:00')\n",
      "(968, 10) (968,)\n",
      "(142, 10) (142,)\n",
      "Run id: 873b33f183e441deafd8d9f264d3ca08\n",
      "Run name: 2011-02-20 23:00:00\n",
      "Batch: 3\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-02-20 23:00:00')\n",
      "Test (current) dates: ('2011-02-21 00:00:00', '2011-02-27 23:00:00')\n",
      "(1133, 10) (1133,)\n",
      "(158, 10) (158,)\n",
      "Run id: ad32f1d9316048baa35102e9c4902b45\n",
      "Run name: 2011-02-27 23:00:00\n",
      "Batch: 4\n",
      "Train dates: ('2011-01-02 00:00:00', '2011-02-27 23:00:00')\n",
      "Test (current) dates: ('2011-02-28 00:00:00', '2011-03-06 23:00:00')\n",
      "(1291, 10) (1291,)\n",
      "(165, 10) (165,)\n",
      "Run id: 7471b3ec81994a259c96181c7a211536\n",
      "Run name: 2011-03-06 23:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ref_end_data = end_date_0\n",
    "FEATURE_COLUMNS = numerical_features + categorical_features\n",
    "\n",
    "# Start a new Run (Parent Run)\n",
    "with mlflow.start_run() as run: \n",
    "    \n",
    "    # Show newly created run metadata info\n",
    "    print(\"Experiment id: {}\".format(run.info.experiment_id))\n",
    "    print(\"Run id: {}\".format(run.info.run_id))\n",
    "    print(\"Run name: {}\".format(run.info.run_name))\n",
    "    \n",
    "    metrics_model = {}\n",
    "    metrics_data = {}\n",
    "    metrics_test = {}\n",
    "    features_historical_drift = []\n",
    "    features_historical_drift_pvalues = []\n",
    "    test_status = 0\n",
    "\n",
    "    #start new run\n",
    "    for k, test_dates in enumerate(experiment_batches):\n",
    "        \n",
    "        print(f\"Batch: {k}\")\n",
    "        \n",
    "        train_dates = start_date_0, ref_end_data\n",
    "        ref_end_data = test_dates[1] # Update reference end date for the next train batch \n",
    "        print(f\"Train dates: {train_dates}\") \n",
    "        print(f\"Test (current) dates: {test_dates}\") \n",
    "        \n",
    "        train_data = raw_data.loc[train_dates[0]:train_dates[1]]\n",
    "        X_train = train_data.loc[:, FEATURE_COLUMNS]\n",
    "        y_train = train_data.loc[:, target]\n",
    "        print(X_train.shape, y_train.shape)\n",
    "        \n",
    "        test_data = raw_data.loc[test_dates[0]:test_dates[1]]\n",
    "        X_test = test_data.loc[:, FEATURE_COLUMNS]\n",
    "        y_test = test_data[target]\n",
    "        print(X_test.shape, y_test.shape)\n",
    "        \n",
    "        # Train model\n",
    "        regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        \n",
    "        # Calculate predictions\n",
    "        ref_prediction = regressor.predict(train_data[FEATURE_COLUMNS])\n",
    "        train_data['prediction'] = ref_prediction\n",
    "        cur_prediction = regressor.predict(test_data[FEATURE_COLUMNS])\n",
    "        test_data['prediction'] = cur_prediction\n",
    "        \n",
    "        \n",
    "        # Calculate Model Quality metrics\n",
    "        regression_quality_report = build_regression_quality_report(\n",
    "            reference_data=train_data, \n",
    "            current_data=test_data,\n",
    "            column_mapping=column_mapping\n",
    "        )\n",
    "        train_metrics = get_regression_quality_metrics(regression_quality_report)\n",
    "        metrics_model.update({test_dates[1]: train_metrics})\n",
    "        \n",
    "        # Calculate Data Drift metrics\n",
    "        data_drift_report = build_data_drift_report(\n",
    "            reference_data=X_train.reset_index(drop=True), \n",
    "            current_data=X_test.reset_index(drop=True),\n",
    "            column_mapping=column_mapping,\n",
    "            drift_share=0.4\n",
    "        )\n",
    "        data_drift_metrics: Dict = get_data_drift_metrics(data_drift_report)\n",
    "        metrics_data.update({test_dates[1]: data_drift_metrics})\n",
    "        \n",
    "        model_quality_report_path = f\"{REPORTS_DIR}/model_quality_report.html\"\n",
    "        regression_quality_report.save_html(model_quality_report_path)\n",
    "        \n",
    "        # Run a Child Run for each Fold \n",
    "        with mlflow.start_run(run_name=test_dates[1], \n",
    "                              nested=True,\n",
    "                              ) as nested_run:\n",
    "            \n",
    "            # Show newly created run metadata info\n",
    "            print(\"Run id: {}\".format(nested_run.info.run_id))\n",
    "            print(\"Run name: {}\".format(nested_run.info.run_name))\n",
    "\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"begin\", test_dates[0])\n",
    "            mlflow.log_param(\"end\", test_dates[1])\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metrics(train_metrics)\n",
    "            mlflow.log_metrics(data_drift_metrics)\n",
    "            \n",
    "            # Log the regression_quality_report as an artifact\n",
    "            mlflow.log_artifact(model_quality_report_path)\n",
    "            \n",
    "            # Log Data Drift report ONLY if drift is detected\n",
    "            if data_drift_metrics['dataset_drift'] is True:\n",
    "                report_date = test_dates[1].split(' ')[0]\n",
    "                data_drift_report_path = f\"../reports/data_drift_report_{report_date}.html\"\n",
    "                data_drift_report.save_html(data_drift_report_path)\n",
    "                mlflow.log_artifact(data_drift_report_path)\n",
    "            \n",
    "    \n",
    "    # Save final  model\n",
    "    joblib.dump(regressor, model_path)\n",
    "    \n",
    "    # Log the last batch model as the parent Run model\n",
    "    mlflow.log_artifact(model_path)\n",
    "    \n",
    "    # Log metrics\n",
    "    avg_model_metrics = pd.DataFrame.from_dict(metrics_model).T.mean().round(3).to_dict()\n",
    "    mlflow.log_metrics(avg_model_metrics)\n",
    "    \n",
    "    avg_data_metrics = pd.DataFrame.from_dict(metrics_data).T.mean().round(3).to_dict()\n",
    "    mlflow.log_metrics(avg_data_metrics)\n",
    "    \n",
    "    # Test the final model \n",
    "    model_test_report = build_model_performance_test_report(\n",
    "        current_data=X_test,\n",
    "        column_mapping=column_mapping,\n",
    "    )\n",
    "    test_status = get_test_status(model_test_report)\n",
    "    if test_status == 0:\n",
    "        print(\"Test failed\")\n",
    "        model_test_report_path = f\"../reports/model_test_report_report.html\"\n",
    "        model_test_report.save_html(model_test_report_path)\n",
    "        mlflow.log_artifact(model_test_report_path)\n",
    "    mlflow.log_metric(\"test_status\", test_status)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
