{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ldpQI0I1rvsc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using MLFlow and Evidently to Evaluate Data Drift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "S7H9fVO5rvsi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this example, we will explore the MLflow integration with Evidently.\n",
    "\n",
    "This notebook shows how you can use the Evidently and MLflow to:\n",
    "* calculate data drift for the model, performed as batch checks \n",
    "* log data drift using MLflow Tracking\n",
    "* explore the result using MLflow UI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qs05Qlgqrvsk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Z8aCer8Yrvsm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Union, Optional\n",
    "\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pbXppBj_rvsn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "More information about the dataset can be found in Kaggle Playground Competition: https://www.kaggle.com/c/bike-sharing-demand/data?select=train.csv\n",
    "\n",
    "Acknowledgement: Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oNrm-FZirvso",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "content = requests.get(\"https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip\").content\n",
    "with zipfile.ZipFile(io.BytesIO(content)) as arc:\n",
    "    raw_data = pd.read_csv(arc.open(\"day.csv\"), header=0, sep=',', parse_dates=['dteday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d0rSZmyOrvso",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant     dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1 2011-01-01       1   0     1        0        6           0   \n",
       "1        2 2011-01-02       1   0     1        0        0           0   \n",
       "2        3 2011-01-03       1   0     1        0        1           1   \n",
       "3        4 2011-01-04       1   0     1        0        2           1   \n",
       "4        5 2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#observe data structure\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6Xa9u5P7rvsp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#set column mapping for Evidently Profile\n",
    "data_columns = ColumnMapping()\n",
    "data_columns.datetime = 'dteday'\n",
    "data_columns.numerical_features = ['weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "data_columns.categorical_features = ['holiday', 'workingday']\n",
    "data_columns.target = 'cnt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qUvh4bd-rvsp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate data drift with Evidently Profile\n",
    "def get_data_drift_report(reference, production, column_mapping) -> Report:\n",
    "    \"\"\"\n",
    "    Returns a list with pairs (feature_name, drift_score)\n",
    "    Drift Score depends on the selected statistical test or distance and the threshold\n",
    "    \"\"\"    \n",
    "    data_drift_report = Report(metrics=[\n",
    "        DataDriftPreset(drift_share=0.4)\n",
    "        ])\n",
    "    data_drift_report.run(reference_data=reference, current_data=production, column_mapping=column_mapping)\n",
    "\n",
    "    return data_drift_report\n",
    "\n",
    "def get_data_drift_metrics(report: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a list with pairs (feature_name, drift_score)\n",
    "    Drift Score depends on the selected statistical test or distance and the threshold\n",
    "    \"\"\" \n",
    "    metrics = {}   \n",
    "    for metric in ['dataset_drift', \n",
    "                   'number_of_drifted_columns', \n",
    "                   'share_of_drifted_columns']: \n",
    "        metrics.update({metric: report[\"metrics\"][0][\"result\"][metric]})\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Experiments\n",
    "\n",
    "- option 1: each period (fold) is a separate experiment Run -> save metrics for each Run\n",
    "- option 2: all folds are part of a single expeirment -> aggrregate metrics\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S1CXPhMcrvsq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set reference dates\n",
    "reference_dates = ('2011-01-01 00:00:00','2011-01-28 23:00:00')\n",
    "\n",
    "# Set experiment batches dates\n",
    "experiment_batches = [\n",
    "    ('2011-01-01 00:00:00','2011-01-29 23:00:00'),\n",
    "    ('2011-01-29 00:00:00','2011-02-07 23:00:00'),\n",
    "    ('2011-02-07 00:00:00','2011-02-14 23:00:00'),\n",
    "    ('2011-02-15 00:00:00','2011-02-21 23:00:00'),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MLFLow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "byVxDBrYrvsr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client tracking uri: http://localhost:5000\n",
      "Experiment ID: 234193429068143937\n"
     ]
    }
   ],
   "source": [
    "from config import EXPERIMENT_NAME, MLFLOW_TRACKING_URI\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"Data Drift\"\n",
    "\n",
    "# Get or Create an experiment by name \n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment: \n",
    "    \n",
    "    experiment_id = experiment.experiment_id if experiment else None\n",
    "    # Show experiment info\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment ID: {}\".format(experiment.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Create_experiment\n",
    "    experiment_id = client.create_experiment(\n",
    "        EXPERIMENT_NAME ,\n",
    "        # artifact_location=MLFLOW_TRACKING_URI,\n",
    "        # tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    "    )\n",
    "    print(\"Experiment ID: {}\".format(experiment_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RunInfo: artifact_uri='mlflow-artifacts:/234193429068143937/22cb151987d146458c17ac951631063b/artifacts', end_time=None, experiment_id='234193429068143937', lifecycle_stage='active', run_id='22cb151987d146458c17ac951631063b', run_name='big-snake-660', run_uuid='22cb151987d146458c17ac951631063b', start_time=1688577393424, status='RUNNING', user_id='mnrozhkov'>\n",
      "<RunInfo: artifact_uri='mlflow-artifacts:/234193429068143937/1b1c3dea510644b49c41537753bab7fc/artifacts', end_time=None, experiment_id='234193429068143937', lifecycle_stage='active', run_id='1b1c3dea510644b49c41537753bab7fc', run_name='dapper-mink-125', run_uuid='1b1c3dea510644b49c41537753bab7fc', start_time=1688577393657, status='RUNNING', user_id='mnrozhkov'>\n",
      "<RunInfo: artifact_uri='mlflow-artifacts:/234193429068143937/f75efe3a785840a6b0bd15b2b2595ff8/artifacts', end_time=None, experiment_id='234193429068143937', lifecycle_stage='active', run_id='f75efe3a785840a6b0bd15b2b2595ff8', run_name='big-stork-138', run_uuid='f75efe3a785840a6b0bd15b2b2595ff8', start_time=1688577393939, status='RUNNING', user_id='mnrozhkov'>\n",
      "<RunInfo: artifact_uri='mlflow-artifacts:/234193429068143937/14866f4df7414756964fc2d1259fb0fb/artifacts', end_time=None, experiment_id='234193429068143937', lifecycle_stage='active', run_id='14866f4df7414756964fc2d1259fb0fb', run_name='fortunate-ape-567', run_uuid='14866f4df7414756964fc2d1259fb0fb', start_time=1688577394177, status='RUNNING', user_id='mnrozhkov'>\n"
     ]
    }
   ],
   "source": [
    "#start new run\n",
    "for date in experiment_batches:\n",
    "    with mlflow.start_run(experiment_id=experiment_id) as run: \n",
    "        \n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"begin\", date[0])\n",
    "        mlflow.log_param(\"end\", date[1])\n",
    "\n",
    "        # Log metrics\n",
    "        report: Dict = get_data_drift_report(\n",
    "            raw_data.loc[raw_data.dteday.between(reference_dates[0], reference_dates[1])], \n",
    "            raw_data.loc[raw_data.dteday.between(date[0], date[1])], \n",
    "            column_mapping=data_columns)\n",
    "        \n",
    "        metrics: Dict = get_data_drift_metrics(report.as_dict())\n",
    "        \n",
    "        for metric in metrics.keys():\n",
    "            mlflow.log_metric(metric, round(metrics[metric], 3))\n",
    "\n",
    "        print(run.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "\n",
    "# feature = 'temp'\n",
    "\n",
    "# # report[\"metrics\"][1][\"result\"][\"drift_by_columns\"][feature][\"drift_score\"]\n",
    "# pprint(list(report[\"metrics\"][1][\"result\"].keys()))\n",
    "# pprint(report[\"metrics\"][1][\"result\"]['share_of_drifted_columns'])\n",
    "# pprint(report[\"metrics\"][1][\"result\"]['dataset_drift'])\n",
    "# pprint(report[\"metrics\"][0])\n",
    "\n",
    "# data_drift_metrics = report[\"metrics\"][0][\"result\"]\n",
    "# pprint(data_drift_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate data drift with Evidently Profile\n",
    "def detect_dataset_drift(reference, production, column_mapping, get_ratio=False):\n",
    "    \"\"\"\n",
    "    Returns True if Data Drift is detected, else returns False.\n",
    "    If get_ratio is True, returns the share of drifted features.\n",
    "    The Data Drift detection depends on the confidence level and the threshold.\n",
    "    For each individual feature Data Drift is detected with the selected confidence (default value is 0.95).\n",
    "    Data Drift for the dataset is detected if share of the drifted features is above the selected threshold (default value is 0.5).\n",
    "    \"\"\"\n",
    "    \n",
    "    data_drift_report = Report(metrics=[\n",
    "        DataDriftPreset(drift_share=0.4)\n",
    "        ])\n",
    "    data_drift_report.run(reference_data=reference, current_data=production, column_mapping=column_mapping)\n",
    "    report = data_drift_report.as_dict()\n",
    "    \n",
    "    if get_ratio:\n",
    "        return report[\"metrics\"][0][\"result\"][\"drift_share\"]\n",
    "    else:\n",
    "        return report[\"metrics\"][0][\"result\"][\"dataset_drift\"]\n",
    "    \n",
    "    \n",
    "#evaluate data drift with Evidently Profile\n",
    "def detect_features_drift(reference, production, column_mapping, get_scores=False):\n",
    "    \"\"\"\n",
    "    Returns True if Data Drift is detected, else returns False. \n",
    "    If get_scores is True, returns scores value (like p-value) for each feature.\n",
    "    The Data Drift detection depends on the confidence level and the threshold.\n",
    "    For each individual feature Data Drift is detected with the selected confidence (default value is 0.95).\n",
    "    \"\"\"\n",
    "    \n",
    "    data_drift_report = Report(metrics=[DataDriftPreset()])\n",
    "    data_drift_report.run(reference_data=reference, current_data=production, column_mapping=column_mapping)\n",
    "    report = data_drift_report.as_dict()\n",
    "    \n",
    "    drifts = []\n",
    "    num_features = column_mapping.numerical_features if column_mapping.numerical_features else []\n",
    "    cat_features = column_mapping.categorical_features if column_mapping.categorical_features else []\n",
    "    for feature in num_features + cat_features:\n",
    "        drift_score = report[\"metrics\"][1][\"result\"][\"drift_by_columns\"][feature][\"drift_score\"]\n",
    "        if get_scores:\n",
    "            drifts.append((feature, drift_score))\n",
    "        else:\n",
    "            drifts.append((feature, report[\"metrics\"][1][\"result\"][\"drift_by_columns\"][feature][\"drift_detected\"]))\n",
    "             \n",
    "    return drifts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drifted_features(drifted_features_data, experiment_batches):\n",
    "    \"\"\"\n",
    "    Plots the drifted features for each batch in the experiment.\n",
    "    \"\"\"\n",
    "    \n",
    "    features_historical_drift_frame = pd.DataFrame(\n",
    "        drifted_features_data, \n",
    "        columns = data_columns.numerical_features + data_columns.categorical_features)\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "                       z = features_historical_drift_frame.astype(int).transpose(),\n",
    "                       x = [x[1] for x in experiment_batches],\n",
    "                       y = data_columns.numerical_features,\n",
    "                       hoverongaps = False,\n",
    "                       xgap = 1,\n",
    "                       ygap = 1,\n",
    "                       zmin = 0,\n",
    "                       zmax = 1,\n",
    "                       showscale = False,\n",
    "                       colorscale = 'Bluered'\n",
    "    ))\n",
    "\n",
    "    fig.update_xaxes(side=\"top\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title = \"Timestamp\",\n",
    "        yaxis_title = \"Feature Drift\"\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "    \n",
    "# fig = plot_drifted_features(features_historical_drift, experiment_batches)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drifted_feature_scores(drifted_features_data, experiment_batches):\n",
    "    \"\"\"\n",
    "    Plots the drifted features for each batch in the experiment.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    drifted_features_data = pd.DataFrame(\n",
    "        drifted_features_data, \n",
    "        columns = data_columns.numerical_features + data_columns.categorical_features)\n",
    "\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "                    z = drifted_features_data.transpose(),\n",
    "                    x = [x[1] for x in experiment_batches],\n",
    "                    y = drifted_features_data.columns,\n",
    "                    hoverongaps = False,\n",
    "                    xgap = 1,\n",
    "                    ygap = 1,\n",
    "                    zmin = 0,\n",
    "                    zmax = 1,\n",
    "                    colorscale = 'reds_r'\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    fig.update_xaxes(side=\"top\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title = \"Timestamp\",\n",
    "        yaxis_title = \"p-value\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# fig = plot_drifted_feature_scores(features_historical_drift_pvalues, experiment_batches)\n",
    "# fig.show(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2011-01-01 00:00:00', '2011-01-29 23:00:00')\n",
      "<RunInfo: artifact_uri='mlflow-artifacts:/234193429068143937/60c4cf25133945a1867b8939ccb32712/artifacts', end_time=None, experiment_id='234193429068143937', lifecycle_stage='active', run_id='60c4cf25133945a1867b8939ccb32712', run_name='spiffy-kit-798', run_uuid='60c4cf25133945a1867b8939ccb32712', start_time=1688577508828, status='RUNNING', user_id='mnrozhkov'>\n",
      "('2011-01-29 00:00:00', '2011-02-07 23:00:00')\n",
      "<RunInfo: artifact_uri='mlflow-artifacts:/234193429068143937/60c4cf25133945a1867b8939ccb32712/artifacts', end_time=None, experiment_id='234193429068143937', lifecycle_stage='active', run_id='60c4cf25133945a1867b8939ccb32712', run_name='spiffy-kit-798', run_uuid='60c4cf25133945a1867b8939ccb32712', start_time=1688577508828, status='RUNNING', user_id='mnrozhkov'>\n",
      "('2011-02-07 00:00:00', '2011-02-14 23:00:00')\n",
      "<RunInfo: artifact_uri='mlflow-artifacts:/234193429068143937/60c4cf25133945a1867b8939ccb32712/artifacts', end_time=None, experiment_id='234193429068143937', lifecycle_stage='active', run_id='60c4cf25133945a1867b8939ccb32712', run_name='spiffy-kit-798', run_uuid='60c4cf25133945a1867b8939ccb32712', start_time=1688577508828, status='RUNNING', user_id='mnrozhkov'>\n",
      "('2011-02-15 00:00:00', '2011-02-21 23:00:00')\n",
      "<RunInfo: artifact_uri='mlflow-artifacts:/234193429068143937/60c4cf25133945a1867b8939ccb32712/artifacts', end_time=None, experiment_id='234193429068143937', lifecycle_stage='active', run_id='60c4cf25133945a1867b8939ccb32712', run_name='spiffy-kit-798', run_uuid='60c4cf25133945a1867b8939ccb32712', start_time=1688577508828, status='RUNNING', user_id='mnrozhkov'>\n"
     ]
    }
   ],
   "source": [
    "###start new run\n",
    "    \n",
    "with mlflow.start_run(experiment_id=experiment_id) as run: \n",
    "    \n",
    "    \n",
    "    features_historical_drift = []\n",
    "    features_historical_drift_pvalues = []\n",
    "    metrics_parent = {}\n",
    "\n",
    "    for date in experiment_batches:\n",
    "        print(date)\n",
    "        \n",
    "        # Calculate Dataset Drift for the fold\n",
    "        with mlflow.start_run(run_name=date[1], \n",
    "                              nested=True,\n",
    "                              experiment_id=experiment_id) as child_run:\n",
    "\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"begin\", date[0])\n",
    "            mlflow.log_param(\"end\", date[1])\n",
    "\n",
    "            # Log metrics\n",
    "            report: Dict = get_data_drift_report(\n",
    "                raw_data.loc[raw_data.dteday.between(reference_dates[0], reference_dates[1])], \n",
    "                raw_data.loc[raw_data.dteday.between(date[0], date[1])], \n",
    "                column_mapping=data_columns)\n",
    "            \n",
    "            metrics: Dict = get_data_drift_metrics(report.as_dict())\n",
    "            ts = int(datetime.strptime(date[1], '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "            \n",
    "            for metric in metrics.keys():\n",
    "                mlflow.log_metric(\n",
    "                    key=metric, \n",
    "                    value=round(metrics[metric], 3), \n",
    "                    step=ts) # use last date as step\n",
    "\n",
    "            print(run.info)\n",
    "            \n",
    "            if metrics['dataset_drift'] is True:\n",
    "                date2str = date[1].replace(\" \", \"-\").replace(\":\", \"-\")\n",
    "                report_path = f\"data_drift_report_{date2str}.html\"\n",
    "                report.save_html(report_path)\n",
    "                mlflow.log_artifact(report_path)\n",
    "                \n",
    "                metrics_parent.update({\"dataset_drift\": metrics['dataset_drift']})\n",
    "\n",
    "        # Log parent Run metrics\n",
    "        mlflow.log_metrics(metrics_parent)\n",
    "        \n",
    "        # Calculate Features Drift \n",
    "        drift_features = detect_features_drift(raw_data.loc[raw_data.dteday.between(reference_dates[0],reference_dates[1])], \n",
    "                           raw_data.loc[raw_data.dteday.between(date[0], date[1])], \n",
    "                           column_mapping=data_columns)\n",
    "        features_historical_drift.append([x[1] for x in drift_features])\n",
    "        fig = plot_drifted_features(features_historical_drift, experiment_batches)\n",
    "        fig.write_html(\"features_drift.html\")\n",
    "        mlflow.log_artifact(\"features_drift.html\")\n",
    "        \n",
    "        \n",
    "        # Calculate Features Drift scores (p-value)\n",
    "        drift_feature_scores = detect_features_drift(\n",
    "            raw_data.loc[raw_data.dteday.between(reference_dates[0], reference_dates[1])], \n",
    "            raw_data.loc[raw_data.dteday.between(date[0], date[1])],\n",
    "            column_mapping=data_columns,\n",
    "            get_scores=True)\n",
    "        features_historical_drift_pvalues.append([x[1] for x in drift_feature_scores])\n",
    "        fig = plot_drifted_feature_scores(features_historical_drift_pvalues, experiment_batches)\n",
    "        fig.write_html(\"features_drift_pvalues.html\")\n",
    "        mlflow.log_artifact(\"features_drift_pvalues.html\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_drift': True,\n",
       " 'number_of_drifted_columns': 4,\n",
       " 'share_of_drifted_columns': 0.5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prdiction Monitoring\n",
    "\n",
    "- monitor predictions for period \n",
    "- use date as a Run name \n",
    "- save report if there is a Drift \n",
    "- run from Python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import TargetDriftPreset, RegressionPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set reference dates\n",
    "reference_dates = ('2011-01-01 00:00:00','2011-01-28 23:00:00')\n",
    "\n",
    "# Set experiment batches dates\n",
    "experiment_batches = [\n",
    "    ('2011-01-01 00:00:00','2011-01-29 23:00:00'),\n",
    "    # ('2011-01-29 00:00:00','2011-02-07 23:00:00'),\n",
    "    # ('2011-02-07 00:00:00','2011-02-14 23:00:00'),\n",
    "    # ('2011-02-15 00:00:00','2011-02-21 23:00:00'),  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client tracking uri: http://localhost:5000\n",
      "Experiment ID: 337416877405482141\n"
     ]
    }
   ],
   "source": [
    "from config import MLFLOW_TRACKING_URI\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "print(f\"Client tracking uri: {client.tracking_uri}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"Prediction Monitoring\"\n",
    "\n",
    "# Get or Create an experiment by name \n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment: \n",
    "    \n",
    "    experiment_id = experiment.experiment_id if experiment else None\n",
    "    # Show experiment info\n",
    "    print(\"Name: {}\".format(experiment.name))\n",
    "    print(\"Experiment ID: {}\".format(experiment.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "    print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Create_experiment\n",
    "    experiment_id = client.create_experiment(\n",
    "        EXPERIMENT_NAME,\n",
    "        # artifact_location=MLFLOW_TRACKING_URI,\n",
    "        # tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    "    )\n",
    "    print(\"Experiment ID: {}\".format(experiment_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data drift with Evidently Profile\n",
    "# def get_data_drift_report(reference, production, column_mapping) -> Report:\n",
    "#     \"\"\"\n",
    "#     Returns a list with pairs (feature_name, drift_score)\n",
    "#     Drift Score depends on the selected statistical test or distance and the threshold\n",
    "#     \"\"\"    \n",
    "\n",
    "\n",
    "#     return num_target_drift_report\n",
    "\n",
    "def get_data_drift_metrics(report: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Returns a list with pairs (feature_name, drift_score)\n",
    "    Drift Score depends on the selected statistical test or distance and the threshold\n",
    "    \"\"\" \n",
    "    metrics = {}   \n",
    "    for metric in ['dataset_drift', \n",
    "                   'number_of_drifted_columns', \n",
    "                   'share_of_drifted_columns']: \n",
    "        metrics.update({metric: report[\"metrics\"][0][\"result\"][metric]})\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start new run\n",
    "for date in experiment_batches:\n",
    "    with mlflow.start_run(experiment_id=experiment_id) as run: \n",
    "        \n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"begin\", date[0])\n",
    "        mlflow.log_param(\"end\", date[1])\n",
    "\n",
    "        # Log metrics\n",
    "        # report: Dict = get_data_drift_report(\n",
    "        #     raw_data.loc[raw_data.dteday.between(reference_dates[0], reference_dates[1])], \n",
    "        #     raw_data.loc[raw_data.dteday.between(date[0], date[1])], \n",
    "        #)\n",
    "        \n",
    "        reference = raw_data.loc[raw_data.dteday.between(reference_dates[0], reference_dates[1])]\n",
    "        production = raw_data.loc[raw_data.dteday.between(date[0], date[1])]\n",
    "        column_mapping=data_columns\n",
    "        \n",
    "        \n",
    "        num_target_drift_report = Report(metrics=[\n",
    "            TargetDriftPreset(),\n",
    "        ])\n",
    "\n",
    "        num_target_drift_report.run(\n",
    "            reference_data=reference, \n",
    "            current_data=production, \n",
    "            column_mapping=column_mapping)\n",
    "        \n",
    "        # reg_performance_report = Report(metrics=[\n",
    "        #     RegressionPreset(),\n",
    "        # ]) \n",
    "        # reg_performance_report.run(reference_data=reference, current_data=production, column_mapping=column_mapping)\n",
    "        \n",
    "        \n",
    "        # metrics: Dict = get_data_drift_metrics(report.as_dict())\n",
    "        \n",
    "        # for metric in metrics.keys():\n",
    "        #     mlflow.log_metric(metric, round(metrics[metric], 3))\n",
    "\n",
    "        # print(run.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnDriftMetric\n",
      "ColumnCorrelationsMetric\n",
      "TargetByFeaturesTable\n"
     ]
    }
   ],
   "source": [
    "target_report = num_target_drift_report.as_dict()\n",
    "\n",
    "for metric in target_report['metrics']:\n",
    "    print(metric['metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
